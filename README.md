# transitive_inference


A simple transitive inference experiment has been performed with a wide variety of species, from fish to birds. Barrett \cite{barrett_2013} uses a Lewis-Skyrms signaling game model to provide a how-possibly account of scrub jays performance in the experiment. The experiment proceeds as follows: Five objects are arranged in a serial order: $A$, $B$, $C$, $D$, $E$. The agent to be tested is conditioned on adjacent pairs in the serial ordering through rewards for selecting the first object in a presented pair. E.g. If presented with $A$-$B$ the agent is rewarded for choosing the item on the left. If presented with $D$-$C$ the agent is rewarded for choosing the item on the right. After the agent has learned to respond correctly to pairs of objects that are adjacent in the serial order, she is then test on the non adjacent pairs $B$-$D$ and $D$-$B$. ($A$ and $E$ are not tested since choosing $A$ is always rewarded and choosing $E$ is never rewarded; thus, choosing the left object in the pair $A$-$C$ might reflect choosing A always having been rewarded rather than reflect the transitive ordering having been represented.) Choosing the correct item in the non-adjacent pairing is then understood as the agent representing the transitive ordering. 

There are a variety of computational models of transitive inference in the literature, of which Barrett and Skyrms' \cite{barrett_skyrms2017self} model is the most transparent. In Barrett and Skyrms model, agents are first conditioned on a full serial ordering of stimuli including non-adjacent pairs. The agents are then presented with a new set of serially ordered stimuli, this time conditioned on only adjacent pairs. Modeling a type of transfer learning, the agents are allowed to transfer some of their dispositions from the first set of stimuli to their dispositions for the new stimuli by allowing initial signals transmitted for the new set of stimuli to be processed as if the signals were the old stimuli. That is, the agents learn to map the new stimuli to their evolved dispositions for the old stimuli, which now serve as an intermediary representation in an agent’s evolution of dispositions for the new stimuli. This allows the agents to infer the appropriate response to a novel pairing of nonadjacent stimuli from the new ordering most of the time.

Many computational models of transitive inference do not explicitly invoke transfer learning. However, this does not entail that transfer learning is not used in the model. For example, Siemann and Delius \cite{siemann_delius_1998} develop a model that makes use of lateral inhibition, whereby, on the transmission of two signals, only the signal of larger magnitude is acted upon. When presented with a stimulus pair from a serial ordering, an agent might initially transmit both a signal to choose the left object and a signal to choose the right object, but only the signal of greater magnitude will go through. On reflection, it is clear that this is a type of transfer learning since the lateral inhibition mechanism is itself a presupposed set of dispositions representing the serial ordering of signal magnitudes. Other models can be even more opaque. De Lillo et al. \cite{delillo_2001} give a three layer neural network model, which, although not explicitly invoking lateral inhibition, is trained using a cost function that always moves the weights in the direction of hidden layer nodes always associating the rewarded stimulus with a greater magnitude than the magnitude associated with the other stimulus in a pair (or always with a smaller magnitude depending on the randomly determined initial state of the network).

All of the models just discussed make diachronic use of transfer learning. Following in spirit Lewis \cite{Lewis1969con} showing that language need not precede establishing conventions, I present a model showing that transfer learning can proceed synchronously. In the model, rather than presenting the agent with pairs of five different stimuli, in the present model involves 20 different stimuli: $A_r$, $A_y$, $A_g$, $A_b$, $B_r$, $B_y$, $B_g$, $B_b$, $C_r$, …, $E_g$, $E_b$. These stimuli might be thought of as four different sides of each of the five objects, red, yellow, green, and blue sides. Thus, in a pairing $C_r$-$B_y$, the object on the right is the correct choice. During the initial phase of the game, a single play of the game proceeds as follows. Nature determines at random with equal probability which sides of a pairing with be observed. If neither side is red, then nature selects any possible combination of the five objects at random with equal probability. If either object presents the red side, then nature only chooses from adjacent pairings at random with equal probability.  During the testing phase of the game, nature only chooses from the pairs $B_r$-$D_r$ and $D_r$-$B_r$. For a variety of reinforcement with punishment parameters, the model achieves success rates well above chance for both the initial and testing phases of the game.
